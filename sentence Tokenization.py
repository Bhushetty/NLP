from nltk.tokenize import sent_tokenize

text = "NLP is easy. Tokenization is the first step."
sentences = sent_tokenize(text)

print(sentences)
